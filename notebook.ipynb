{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53683431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45272\n",
      "22636\n",
      "22636\n",
      "(1, 4, 32, 32)\n",
      "22636\n",
      "finish data\n",
      "[0 2 3 4 5 6]\n",
      "['01_radvess' '02_radvess' '03_radvess' '04_radvess' '05_radvess'\n",
      " '06_radvess' '07_radvess' '08_radvess' '09_radvess' '1001_cremad'\n",
      " '1002_cremad' '1003_cremad' '1004_cremad' '1005_cremad' '1006_cremad'\n",
      " '1007_cremad' '1008_cremad' '1009_cremad' '1010_cremad' '1011_cremad'\n",
      " '1012_cremad' '1013_cremad' '1014_cremad' '1015_cremad' '1016_cremad'\n",
      " '1017_cremad' '1018_cremad' '1019_cremad' '1020_cremad' '1021_cremad'\n",
      " '1022_cremad' '1023_cremad' '1024_cremad' '1025_cremad' '1026_cremad'\n",
      " '1027_cremad' '1028_cremad' '1029_cremad' '1030_cremad' '1031_cremad'\n",
      " '1032_cremad' '1033_cremad' '1034_cremad' '1035_cremad' '1036_cremad'\n",
      " '1037_cremad' '1038_cremad' '1039_cremad' '1040_cremad' '1041_cremad'\n",
      " '1042_cremad' '1043_cremad' '1044_cremad' '1045_cremad' '1046_cremad'\n",
      " '1047_cremad' '1048_cremad' '1049_cremad' '1050_cremad' '1051_cremad'\n",
      " '1052_cremad' '1053_cremad' '1054_cremad' '1055_cremad' '1056_cremad'\n",
      " '1057_cremad' '1058_cremad' '1059_cremad' '1060_cremad' '1061_cremad'\n",
      " '1062_cremad' '1063_cremad' '1064_cremad' '1065_cremad' '1066_cremad'\n",
      " '1067_cremad' '1068_cremad' '1069_cremad' '1070_cremad' '1071_cremad'\n",
      " '1072_cremad' '1073_cremad' '1074_cremad' '1075_cremad' '1076_cremad'\n",
      " '1077_cremad' '1078_cremad' '1079_cremad' '1080_cremad' '1081_cremad'\n",
      " '1082_cremad' '1083_cremad' '1084_cremad' '1085_cremad' '1086_cremad'\n",
      " '1087_cremad' '1088_cremad' '1089_cremad' '1090_cremad' '1091_cremad'\n",
      " '10_radvess' '11_radvess' '12_radvess' '13_radvess' '14_radvess'\n",
      " '15_radvess' '16_radvess' '17_radvess' '18_radvess' '19_radvess'\n",
      " '20_radvess' '21_radvess' '22_radvess' '23_radvess' '24_radvess'\n",
      " 'DC_savee' 'JE_savee' 'JK_savee' 'KL_savee' 'OAF_tess' 'YAF_tess']\n",
      "[0 2 3 4 5 6]\n",
      "finish data\n",
      "(8, 22636, 32, 32)\n",
      "(22636, 32, 32, 8)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import kagglehub\n",
    "# import statsmodels.api as sm\n",
    "\n",
    "# import tensorflow_addons as tfa\n",
    "import cv2\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import math\n",
    "from sklearn.datasets import load_iris\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, BatchNormalization, Dropout, Conv2D, MaxPooling2D, Flatten, AveragePooling2D, Activation, Concatenate\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from keras.datasets import mnist\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy, TopKCategoricalAccuracy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "\n",
    "import logging, os\n",
    "\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly\n",
    "from scipy.io import wavfile\n",
    "from scipy.fftpack import fft\n",
    "import cv2\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "from glob import glob\n",
    "import skimage\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.image import resize\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping,ModelCheckpoint,LearningRateScheduler\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from pydub import AudioSegment\n",
    "from tqdm import tqdm\n",
    "import tempfile\n",
    "\n",
    "from tensorflow.keras import regularizers\n",
    "tf.debugging.set_log_device_placement(False)\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.metrics import Metric\n",
    "\n",
    "if os.path.isfile(\"myData.npz\"):\n",
    "    print(\"✅ 'data.npz' exists.\")\n",
    "    with np.load(\"myData.npz\") as data:\n",
    "        myData = data['myData']\n",
    "        myData2 = data['myData2']\n",
    "        myY = data['myY']\n",
    "        myActors = data['myActors']\n",
    "        myDatasets = data['myDatasets']\n",
    "        myHasNoise = data['myHasNoise']\n",
    "        print(np.unique(myY))\n",
    "        print(np.unique(myActors))\n",
    "else:\n",
    "\n",
    "    folder = './savefiles'\n",
    "\n",
    "    def findFilesFromPattern(pattern):\n",
    "        pattern = re.compile(pattern + r'_(.*?)_(.*?)_(.*?)_(\\d+)_(\\d+)\\.npy')\n",
    "        heatmaps_dict = {}\n",
    "\n",
    "        for filename in os.listdir(folder):\n",
    "            match = pattern.match(filename)\n",
    "            if match:\n",
    "                dataset, actor, emotion, i, j = map(str, match.groups())\n",
    "                i, j = int(i), int(j)\n",
    "                filepath = os.path.join(folder, filename)\n",
    "                data = np.load(filepath)\n",
    "\n",
    "                heatmaps_dict[f'{dataset}_{actor}_{emotion}_{j // 2}_{j%2}'] = {'data': data, 'dataset': dataset, 'actor': actor, 'emotion':emotion, 'type': j, 'has_noise': (j%4 == 0 or j%4==1)}\n",
    "\n",
    "        return heatmaps_dict\n",
    "\n",
    "    mfccwasserstein = findFilesFromPattern('wassersteinMfccHeat')\n",
    "    melwasserstein = findFilesFromPattern('wassersteinHeat')\n",
    "    meltimeeuclid = findFilesFromPattern('timeMetricHeat')\n",
    "    meleuclid = findFilesFromPattern('euclideanHeat')\n",
    "\n",
    "    def load_spectrograms(prefixes, path='./savefiles'):\n",
    "        patterns = []\n",
    "        for prefix in prefixes:\n",
    "            patterns.append(os.path.join(path, f\"{prefix}_*.npy\"))\n",
    "        my_globs = glob(patterns[0])\n",
    "        for pattern in patterns[1:]:\n",
    "            my_globs = my_globs + glob(pattern)\n",
    "        file_list = sorted(my_globs)\n",
    "        return [np.load(file) for i, file in enumerate(file_list)]\n",
    "\n",
    "    myRaw = load_spectrograms([\"savee\", 'tess', 'radvess', 'cremad'])\n",
    "    print(len(mfccwasserstein))\n",
    "    print(len([mfccwasserstein[key]['data'] for key in sorted(mfccwasserstein.keys()) if mfccwasserstein[key]['type'] % 2 == 0]))\n",
    "    print(len([mfccwasserstein[key]['data'] for key in sorted(mfccwasserstein.keys()) if mfccwasserstein[key]['type'] % 2 == 1]))\n",
    "    print(np.array([[meleuclid[key]['data'] for key in sorted(meleuclid.keys()) if meleuclid[key]['type'] == 0]]).shape)\n",
    "\n",
    "    print(len(myRaw))\n",
    "\n",
    "    myData = np.array([myRaw])\n",
    "    print('finish data')\n",
    "    myData = myData.astype('float32')\n",
    "    myData = np.transpose(myData, (1, 2, 3, 0))\n",
    "    myEmotionMap = {\n",
    "        'neutral': 1, 'calm':2, 'happy':3, 'sad':4, 'angry':5, 'fearful':6, 'disgust':7, 'surprised':8\n",
    "    }\n",
    "    myY = np.array(\n",
    "        [myEmotionMap[mfccwasserstein[key]['emotion']] -1 for key in sorted(mfccwasserstein.keys()) if mfccwasserstein[key]['type'] % 2 == 0]\n",
    "    )\n",
    "    print(np.unique(myY))\n",
    "    myActors = np.array(\n",
    "        [mfccwasserstein[key]['actor'] + '_' + mfccwasserstein[key]['dataset']  for key in sorted(mfccwasserstein.keys()) if mfccwasserstein[key]['type'] % 2 == 0]\n",
    "    )\n",
    "    myDatasets = np.array(\n",
    "        [mfccwasserstein[key]['dataset']  for key in sorted(mfccwasserstein.keys()) if mfccwasserstein[key]['type'] % 2 == 0]\n",
    "    )\n",
    "    myHasNoise = np.array(\n",
    "        [mfccwasserstein[key]['has_noise']  for key in sorted(mfccwasserstein.keys()) if mfccwasserstein[key]['type'] % 2 == 0]\n",
    "    )\n",
    "    print(np.unique(myActors))\n",
    "\n",
    "    print(np.unique(myY))\n",
    "    myY = [x -1 if x > 0 else x for x in myY]\n",
    "    myY = to_categorical(myY, num_classes=6)\n",
    "\n",
    "    myData2 = np.array([\n",
    "                        [meleuclid[key]['data'] for key in sorted(meleuclid.keys()) if meleuclid[key]['type'] % 2 == 0],\n",
    "                        [meleuclid[key]['data'] for key in sorted(meleuclid.keys()) if meleuclid[key]['type'] % 2 == 1],\n",
    "                        [meltimeeuclid[key]['data'] for key in sorted(meltimeeuclid.keys()) if meltimeeuclid[key]['type'] % 2 == 0],\n",
    "                        [meltimeeuclid[key]['data'] for key in sorted(meltimeeuclid.keys()) if meltimeeuclid[key]['type'] % 2 == 1],\n",
    "                        [mfccwasserstein[key]['data'] for key in sorted(mfccwasserstein.keys()) if mfccwasserstein[key]['type'] % 2 == 0],\n",
    "                        [mfccwasserstein[key]['data'] for key in sorted(mfccwasserstein.keys()) if mfccwasserstein[key]['type'] % 2 == 1],\n",
    "                        [melwasserstein[key]['data'] for key in sorted(melwasserstein.keys()) if melwasserstein[key]['type'] % 2 == 0],\n",
    "                        [melwasserstein[key]['data'] for key in sorted(melwasserstein.keys()) if melwasserstein[key]['type'] % 2 == 1]\n",
    "                        ])\n",
    "    print('finish data')\n",
    "    myData2 = myData2.astype('float32')\n",
    "    print(myData2.shape)\n",
    "    myData2 = np.transpose(myData2, (1, 2, 3, 0))\n",
    "    print(myData2.shape)\n",
    "\n",
    "    def upload_to_gcs(bucket_name, source_file, destination_blob):\n",
    "        \"\"\"Upload a file to a GCS bucket.\"\"\"\n",
    "        client = storage.Client()\n",
    "        bucket = client.bucket(bucket_name)\n",
    "        blob = bucket.blob(destination_blob)\n",
    "        blob.upload_from_filename(source_file)\n",
    "        print(f\"✅ Uploaded {destination_blob} to gs://{bucket_name}/{destination_blob}\")\n",
    "\n",
    "    np.savez_compressed(\n",
    "        \"myData.npz\",\n",
    "        myData=myData,\n",
    "        myData2=myData2,\n",
    "        myY=myY,\n",
    "        myActors=myActors,\n",
    "        myDatasets=myDatasets,\n",
    "        myHasNoise=myHasNoise\n",
    "    )\n",
    "\n",
    "    GCS_BUCKET = \"simplicialcomplex-outputbucket\"\n",
    "\n",
    "    # upload_to_gcs(GCS_BUCKET, \"myData.npz\", \"data/myData.npz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49612dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 4, 3, 3], expected input[256, 8, 32, 32] to have 4 channels, but got 8 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 262\u001b[39m\n\u001b[32m    259\u001b[39m fusion_optimizer.zero_grad()\n\u001b[32m    261\u001b[39m outputs = model(X_batch)\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m outputs2 = \u001b[43mmodel2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX2_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    263\u001b[39m loss = criterion(outputs, y_batch)\n\u001b[32m    264\u001b[39m loss2 = criterion(outputs2, y_batch)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 146\u001b[39m, in \u001b[36mCNNModel2.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    147\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.classifier(x)\n\u001b[32m    148\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[33;03mRuns the forward pass.\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/conv.py:548\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/conv.py:543\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    533\u001b[39m         F.pad(\n\u001b[32m    534\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    541\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    542\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m543\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Given groups=1, weight of size [64, 4, 3, 3], expected input[256, 8, 32, 32] to have 4 channels, but got 8 channels instead"
     ]
    }
   ],
   "source": [
    "splitter = GroupShuffleSplit(test_size=0.2, n_splits=1)\n",
    "groups = myActors#np.array([f\"{d}_{a}_{c}\" for d, a, c in zip(myActors, myDatasets)])\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def stratified_group_split_3way(y, groups, val_size=0.2, test_size=0.2, random_state=42):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    df = pd.DataFrame({'y': y, 'group': groups})\n",
    "\n",
    "    group_labels = (\n",
    "        df.groupby('group')['y']\n",
    "          .agg(lambda s: s.value_counts().index[0])\n",
    "          .reset_index()\n",
    "    )\n",
    "\n",
    "    sss_outer = StratifiedShuffleSplit(\n",
    "        n_splits=1, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    sss_inner = StratifiedShuffleSplit(\n",
    "        n_splits=1, test_size=val_size/(1 - test_size), random_state=random_state + 1\n",
    "    )\n",
    "\n",
    "    group_indices = np.arange(len(group_labels))\n",
    "    for trainval_g, test_g in sss_outer.split(group_indices, group_labels['y']):\n",
    "        trainval_groups = group_labels['group'].iloc[trainval_g].values\n",
    "        test_groups = group_labels['group'].iloc[test_g].values\n",
    "\n",
    "        trainval_df = group_labels.iloc[trainval_g]\n",
    "        trainval_idx = np.arange(len(trainval_df))\n",
    "\n",
    "        for train_g, val_g in sss_inner.split(trainval_idx, trainval_df['y']):\n",
    "            train_groups = trainval_df['group'].iloc[train_g].values\n",
    "            val_groups = trainval_df['group'].iloc[val_g].values\n",
    "\n",
    "    # Map back to samples\n",
    "    train_mask = df['group'].isin(train_groups)\n",
    "    val_mask = df['group'].isin(val_groups)\n",
    "    test_mask = df['group'].isin(test_groups)\n",
    "\n",
    "    train_idx = np.where(train_mask)[0]\n",
    "    val_idx = np.where(val_mask)[0]\n",
    "    test_idx = np.where(test_mask)[0]\n",
    "\n",
    "    return train_idx, val_idx, test_idx\n",
    "\n",
    "\n",
    "train_idx, val_idx, test_idx = stratified_group_split_3way(y=np.argmax(myY, axis=1), groups=groups, val_size=0.1, test_size=0.2)\n",
    "\n",
    "X_train, X_val, X_test, X_train2, X_val2, X_test2 = myData[train_idx], myData[val_idx], myData[test_idx], myData2[train_idx], myData2[val_idx], myData2[test_idx]\n",
    "y_train, y_val, y_test = myY[train_idx], myY[val_idx], myY[test_idx]\n",
    "\n",
    "\n",
    "# X_train, X_test, X_train2, X_test2, y_train, y_test = train_test_split(\n",
    "#     myData, myData2, myY, test_size=0.2, shuffle=True, stratify=myActors, random_state=20\n",
    "# )\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split, Subset\n",
    "from torchmetrics.classification import MulticlassAUROC, MulticlassAccuracy\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Model definition ---\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.AvgPool2d(2),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.AvgPool2d(2),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64, 64),  # for input 32×32 after two poolings\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 64),  # for input 32×32 after two poolings\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "class CNNModel2(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(CNNModel2, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(8, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64, 64),  # for input 32×32 after two poolings\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 64),  # for input 32×32 after two poolings\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "class FusionNet(nn.Module):\n",
    "    def __init__(self, num_classes, dropout_prob=0.2):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout_prob)\n",
    "        self.fc = nn.Linear(num_classes * 2, num_classes)  # combine logits/features\n",
    "\n",
    "    def forward(self, logits1, logits2):\n",
    "        # Concatenate logits from two models\n",
    "        x = torch.cat([logits1, logits2], dim=1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "def entropy_from_logits(logits):\n",
    "    # logits: (B, C)\n",
    "    p = F.softmax(logits, dim=1)\n",
    "    return -(p * (p.clamp_min(1e-8)).log()).sum(dim=1, keepdim=True)  # (B,1)\n",
    "\n",
    "class FusionNetGated(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # small gate that looks at confidences (entropies) and max probs\n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Linear(4, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)  # outputs logit for alpha\n",
    "        )\n",
    "\n",
    "    def forward(self, logits1, logits2):\n",
    "        # Build reliability features\n",
    "        e1 = entropy_from_logits(logits1)              # (B,1)\n",
    "        e2 = entropy_from_logits(logits2)              # (B,1)\n",
    "        m1 = F.softmax(logits1, dim=1).amax(dim=1, keepdim=True)  # (B,1)\n",
    "        m2 = F.softmax(logits2, dim=1).amax(dim=1, keepdim=True)  # (B,1)\n",
    "        feats = torch.cat([e1, e2, m1, m2], dim=1)     # (B,4)\n",
    "\n",
    "        alpha = torch.sigmoid(self.gate(feats))        # (B,1) in (0,1)\n",
    "        fused = alpha * logits1 + (1 - alpha) * logits2\n",
    "        return fused, alpha\n",
    "\n",
    "\n",
    "# --- Instantiate model ---\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = CNNModel(num_classes=6).to(device)\n",
    "model2 = CNNModel2(num_classes=6).to(device)\n",
    "\n",
    "# --- Loss and optimizer ---\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "optimizer2 = torch.optim.Adam(model2.parameters(), lr=1e-3)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train.transpose(0, 3, 1, 2), dtype=torch.float32)\n",
    "X_train2_tensor = torch.tensor(X_train2.transpose(0, 3, 1, 2), dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(np.argmax(y_train, axis=1), dtype=torch.long)\n",
    "\n",
    "has_noise_idx = np.where(myHasNoise[val_idx] == 0)[0]\n",
    "X_val_tensor = torch.tensor(X_val[has_noise_idx].transpose(0, 3, 1, 2), dtype=torch.float32)\n",
    "X_val2_tensor = torch.tensor(X_val2[has_noise_idx].transpose(0, 3, 1, 2), dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(np.argmax(y_val[has_noise_idx], axis=1), dtype=torch.long)\n",
    "\n",
    "has_noise_idx = np.where(myHasNoise[test_idx] == 0)[0]\n",
    "X_test_tensor = torch.tensor(X_test[has_noise_idx].transpose(0, 3, 1, 2), dtype=torch.float32)\n",
    "X_test2_tensor = torch.tensor(X_test2[has_noise_idx].transpose(0, 3, 1, 2), dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(np.argmax(y_test[has_noise_idx], axis=1), dtype=torch.long)\n",
    "\n",
    "dataset = TensorDataset(X_train_tensor, X_train2_tensor, y_train_tensor)\n",
    "val_ds = TensorDataset(X_val_tensor, X_val2_tensor, y_val_tensor)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=256, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=256)\n",
    "test_loader = DataLoader(TensorDataset(X_test_tensor, X_test2_tensor, y_test_tensor), batch_size=256)\n",
    "\n",
    "# ================================================================\n",
    "# Training Setup\n",
    "# ================================================================\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")  # Apple GPU\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # NVIDIA GPU (if any)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")   # fallback\n",
    "model = CNNModel().to(device)\n",
    "model2 = CNNModel2().to(device)\n",
    "\n",
    "\n",
    "fusion = FusionNetGated().to(device)\n",
    "fusion_optimizer = torch.optim.Adam(fusion.parameters(), lr=1e-3)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "optimizer= optim.Adam(model.parameters())\n",
    "optimizer2= optim.Adam(model2.parameters())\n",
    "num_epochs = 40\n",
    "\n",
    "best_val_auc = 0.0\n",
    "auroc = MulticlassAUROC(num_classes=6, average='macro').to(device)\n",
    "top3acc = MulticlassAccuracy(num_classes=6, top_k=3).to(device)\n",
    "\n",
    "# ================================================================\n",
    "# Training Loop with Checkpoint\n",
    "# ================================================================\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_preds, train_labels = [], []\n",
    "    for X_batch, X2_batch, y_batch in train_loader:\n",
    "        X_batch, X2_batch, y_batch = X_batch.to(device), X2_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        optimizer2.zero_grad()\n",
    "        fusion_optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(X_batch)\n",
    "        outputs2 = model2(X2_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss2 = criterion(outputs2, y_batch)\n",
    "        # combined_logits = fusion(outputs, outputs2)\n",
    "        # loss3 = criterion(combined_logits, y_batch)\n",
    "        # loss3.backward()\n",
    "\n",
    "        combined_logits, alpha = fusion(outputs, outputs2)\n",
    "        loss = criterion(combined_logits, y_batch)\n",
    "\n",
    "        # optional deep supervision helps\n",
    "        loss = loss + 0.2*criterion(outputs, y_batch) + 0.2*criterion(outputs2, y_batch)\n",
    "        loss.backward()\n",
    "\n",
    "        train_preds.append(torch.softmax(combined_logits, dim=1))\n",
    "        train_labels.append(y_batch)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        optimizer2.step()\n",
    "\n",
    "        fusion_optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_preds, val_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for X_val, X2_val, y_val in val_loader:\n",
    "            X_val, X2_val, y_val = X_val.to(device), X2_val.to(device), y_val.to(device)\n",
    "            outputs = model(X_val)\n",
    "            outputs2 = model2(X2_val)\n",
    "\n",
    "            # combined_logits = fusion(outputs, outputs2)\n",
    "            combined_logits, alpha = fusion(outputs, outputs2)\n",
    "            preds = torch.softmax(combined_logits, dim=1)\n",
    "            val_preds.append(preds)\n",
    "            val_labels.append(y_val)\n",
    "    val_preds = torch.cat(val_preds)\n",
    "    val_labels = torch.cat(val_labels)\n",
    "\n",
    "    val_auc = auroc(val_preds, val_labels).item()\n",
    "    val_top3 = top3acc(val_preds, val_labels).item()\n",
    "\n",
    "    y_pred = torch.argmax(val_preds, dim=1)\n",
    "\n",
    "    accuracy = (y_pred == val_labels).float().mean()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - val_auc: {val_auc:.4f} - top3_acc: {val_top3:.4f} - val_acc: {accuracy.item():.4f}\")\n",
    "\n",
    "    # Save best model\n",
    "    if accuracy.item() > best_val_auc:\n",
    "        best_val_auc = accuracy.item()\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        torch.save(model2.state_dict(), \"best_model2.pth\")\n",
    "        torch.save(fusion.state_dict(), \"best_model3.pth\")\n",
    "        print(\"✅ Saved new best model.\")\n",
    "\n",
    "    train_preds = torch.cat(train_preds)\n",
    "    train_labels = torch.cat(train_labels)\n",
    "    val_auc = auroc(train_preds, train_labels).item()\n",
    "    val_top3 = top3acc(train_preds, train_labels).item()\n",
    "\n",
    "    y_pred = torch.argmax(train_preds, dim=1)\n",
    "\n",
    "    accuracy = (y_pred == train_labels).float().mean()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - train_auc: {val_auc:.4f} - train_top3_acc: {val_top3:.4f} - train_acc: {accuracy.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37b4919b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/40 - val_auc: 0.8514 - top3_acc: 0.8844 - val_acc: 0.5309\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.49      0.80      0.61       246\n",
      "       happy       0.43      0.59      0.49       297\n",
      "         sad       0.52      0.50      0.51       297\n",
      "       angry       0.72      0.58      0.64       297\n",
      "     fearful       0.66      0.31      0.42       297\n",
      "     disgust       0.54      0.46      0.50       297\n",
      "\n",
      "    accuracy                           0.53      1731\n",
      "   macro avg       0.56      0.54      0.53      1731\n",
      "weighted avg       0.56      0.53      0.52      1731\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# ================================================================\n",
    "# Evaluation\n",
    "# ================================================================\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "model2.load_state_dict(torch.load(\"best_model2.pth\"))\n",
    "fusion.load_state_dict(torch.load(\"best_model3.pth\"))\n",
    "model.eval()\n",
    "model2.eval()\n",
    "fusion.eval()\n",
    "\n",
    "all_preds, all_labels, all_preds2, all_labels2 = [], [], [], []\n",
    "with torch.no_grad():\n",
    "    for X_batch, X2_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        X2_batch = X2_batch.to(device)\n",
    "        outputs = model(X_batch)\n",
    "        outputs2 = model2(X2_batch)\n",
    "\n",
    "        # combined_logits = fusion(outputs, outputs2)\n",
    "        combined_logits, alpha = fusion(outputs, outputs2)\n",
    "        # preds = torch.softmax(combined_logits, dim=1)\n",
    "        preds = torch.argmax(combined_logits, dim=1).cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_preds2.append(torch.softmax(combined_logits, dim=1))\n",
    "        all_labels.extend(y_batch.numpy())\n",
    "        all_labels2.append(y_batch.to(device))\n",
    "\n",
    "    val_preds = torch.cat(all_preds2)\n",
    "    val_labels = torch.cat(all_labels2)\n",
    "    val_auc = auroc(val_preds, val_labels).item()\n",
    "    val_top3 = top3acc(val_preds, val_labels).item()\n",
    "\n",
    "    y_pred = torch.argmax(val_preds, dim=1)\n",
    "\n",
    "    accuracy = (y_pred == val_labels).float().mean()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - val_auc: {val_auc:.4f} - top3_acc: {val_top3:.4f} - val_acc: {accuracy.item():.4f}\")\n",
    "\n",
    "# Classification report\n",
    "class_labels = ['neutral', 'happy', 'sad', 'angry', 'fearful', 'disgust']\n",
    "report = classification_report(all_labels, all_preds, target_names=class_labels)\n",
    "print(report)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "cm_df = pd.DataFrame(cm, index=class_labels, columns=class_labels)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a8ae72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_idx, test_idx = stratified_group_shuffle_split(y=np.argmax(myY, axis=1), groups=groups, test_size=0.2)\n",
    "\n",
    "X_train, X_test = myData[train_idx], myData[test_idx]\n",
    "y_train, y_test = myY[train_idx], myY[test_idx]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     myData, myY, test_size=0.2, shuffle=True, stratify=myY, random_state=20\n",
    "# )\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split, Subset\n",
    "from torchmetrics.classification import MulticlassAUROC, MulticlassAccuracy\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ================================================================\n",
    "# Model Definition\n",
    "# ================================================================\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.AvgPool2d(2),\n",
    "\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.AvgPool2d(2),\n",
    "\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 4, 64),  # for input 32×32 after two poolings\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 64),  # for input 32×32 after two poolings\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# Data Preparation\n",
    "# ================================================================\n",
    "# Assume X_train, y_train, X_test, y_test are numpy arrays\n",
    "# Shapes: X: (N, 32, 32, 8), y: one-hot (N, 7)\n",
    "print(X_train.shape)\n",
    "X_train_tensor = torch.tensor(X_train.transpose(0, 3, 1, 2), dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(np.argmax(y_train, axis=1), dtype=torch.long)\n",
    "has_noise_idx = np.where(myHasNoise[test_idx] == 0)[0]\n",
    "X_test_tensor = torch.tensor(X_test[has_noise_idx].transpose(0, 3, 1, 2), dtype=torch.float32)\n",
    "# X_test2_tensor = torch.tensor(X_test2[has_noise_idx].transpose(0, 3, 1, 2), dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(np.argmax(y_test[has_noise_idx], axis=1), dtype=torch.long)\n",
    "\n",
    "dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_idx, val_idx = stratified_group_shuffle_split(y=np.argmax(y_train, axis=1), groups=groups[train_idx], test_size=0.2)\n",
    "\n",
    "train_ds = Subset(dataset, train_idx)\n",
    "val_ds = Subset(dataset, val_idx)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=1024, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=1024)\n",
    "test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=256)\n",
    "\n",
    "# ================================================================\n",
    "# Training Setup\n",
    "# ================================================================\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")  # Apple GPU\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # NVIDIA GPU (if any)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")   # fallback\n",
    "model = CNNModel().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "num_epochs = 20\n",
    "\n",
    "best_val_auc = 0.0\n",
    "auroc = MulticlassAUROC(num_classes=6, average='macro').to(device)\n",
    "top3acc = MulticlassAccuracy(num_classes=6, top_k=3).to(device)\n",
    "\n",
    "# ================================================================\n",
    "# Training Loop with Checkpoint\n",
    "# ================================================================\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_preds, val_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for X_val, y_val in val_loader:\n",
    "            X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "            outputs = model(X_val)\n",
    "            preds = torch.softmax(outputs, dim=1)\n",
    "            val_preds.append(preds)\n",
    "            val_labels.append(y_val)\n",
    "    val_preds = torch.cat(val_preds)\n",
    "    val_labels = torch.cat(val_labels)\n",
    "\n",
    "    val_auc = auroc(val_preds, val_labels).item()\n",
    "    val_top3 = top3acc(val_preds, val_labels).item()\n",
    "\n",
    "    y_pred = torch.argmax(val_preds, dim=1)\n",
    "\n",
    "    accuracy = (y_pred == val_labels).float().mean()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - val_auc: {val_auc:.4f} - top3_acc: {val_top3:.4f} - val_acc: {accuracy.item():.4f}\")\n",
    "\n",
    "    # Save best model\n",
    "    if accuracy.item() > best_val_auc:\n",
    "        best_val_auc = accuracy.item()\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        print(\"✅ Saved new best model.\")\n",
    "\n",
    "# ================================================================\n",
    "# Evaluation\n",
    "# ================================================================\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "all_preds, all_labels, all_preds2, all_labels2 = [], [], [], []\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        outputs = model(X_batch)\n",
    "        preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_preds2.append(torch.softmax(outputs, dim=1))\n",
    "        all_labels.extend(y_batch.numpy())\n",
    "        all_labels2.append(y_batch.to(device))\n",
    "\n",
    "    val_preds = torch.cat(all_preds2)\n",
    "    val_labels = torch.cat(all_labels2)\n",
    "    val_auc = auroc(val_preds, val_labels).item()\n",
    "    val_top3 = top3acc(val_preds, val_labels).item()\n",
    "\n",
    "    y_pred = torch.argmax(val_preds, dim=1)\n",
    "\n",
    "    accuracy = (y_pred == val_labels).float().mean()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - val_auc: {val_auc:.4f} - top3_acc: {val_top3:.4f} - val_acc: {accuracy.item():.4f}\")\n",
    "\n",
    "\n",
    "# Classification report\n",
    "class_labels = ['neutral', 'happy', 'sad', 'angry', 'fearful', 'disgust']\n",
    "report = classification_report(all_labels, all_preds, target_names=class_labels)\n",
    "print(report)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "cm_df = pd.DataFrame(cm, index=class_labels, columns=class_labels)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e75a2ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
